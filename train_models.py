import os
import json
import pandas as pd
import numpy as np
from utils.data_preprocessing import (
    load_and_preprocess_locations_data,
    load_and_preprocess_demand_data,
    load_and_preprocess_segmentation_data
)
from models.location_analyzer import LocationAnalyzer
from models.demand_forecaster import DemandForecaster
from models.client_segmenter import ClientSegmenter
import time
import traceback

def create_directories():
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
    directories = [
        'models/saved_models',
        'data/synthetic',
        'reports'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞–Ω–∞: {directory}")

def train_location_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–π"""
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–π...")
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X, y, features = load_and_preprocess_locations_data(
            'data/synthetic/locations_data.json'
        )
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(X)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏: {features}")
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        analyzer = LocationAnalyzer()
        r2 = analyzer.train(X, y, features)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        analyzer.save_model()
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–π –æ–±—É—á–µ–Ω–∞. R¬≤ = {r2:.3f}")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–π: {e}")
        print(f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return False

def train_demand_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞"""
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞...")
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X, y, features, df = load_and_preprocess_demand_data(
            'data/synthetic/demand_forecast_data.json'
        )
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {df['category'].unique()}")
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        forecaster = DemandForecaster()
        success = forecaster.train(X, y, features, df)
        
        if success:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            forecaster.save_models()
            print("‚úÖ –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
            return True
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞: {e}")
        print(f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return False

def train_segmentation_model():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤"""
    print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤...")
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X, y, features, segment_mapping = load_and_preprocess_segmentation_data(
            'data/synthetic/b2b_segmentation_data.json'
        )
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(X)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segment_mapping)}")
        print(f"–°–µ–≥–º–µ–Ω—Ç—ã: {list(segment_mapping.values())}")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
        if not pd.api.types.is_numeric_dtype(y):
            print("‚ö†Ô∏è –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ —á–∏—Å–ª–æ–≤–∞—è. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç...")
            y = pd.Series(y).astype('category').cat.codes
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        segmenter = ClientSegmenter()
        success = segmenter.train(X, y, features, segment_mapping)
        
        if success:
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            if segmenter.save_models():
                print("‚úÖ –ú–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
                return True
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤")
                return False
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤: {e}")
        print(f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return False

def generate_sample_predictions():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
    
    try:
        # 1. –ü—Ä–∏–º–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–∏
        location_analyzer = LocationAnalyzer.load_model()
        location_pred = location_analyzer.predict(
            pedestrian_traffic=12500,
            avg_purchase_value=1200,
            district='central'
        )
        
        print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞—Ü–∏–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
        
        # 2. –ü—Ä–∏–º–µ—Ä –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞
        demand_forecaster = DemandForecaster.load_models()
        demand_pred = demand_forecaster.predict(
            category='electronics',
            region='REG_MSK',
            economic_index=105.0
        )
        
        print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–ø—Ä–æ—Å–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
        
        # 3. –ü—Ä–∏–º–µ—Ä –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞
        client_segmenter = ClientSegmenter.load_models()
        if hasattr(client_segmenter, 'classifier') and client_segmenter.classifier is not None:
            segment_pred = client_segmenter.predict_segment(
                recency=15,
                frequency=12,
                monetary=5000000,
                company_size='medium'
            )
            print("‚úÖ –ü—Ä–∏–º–µ—Ä –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
        else:
            print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä")
            segment_pred = {
                'segment_id': 1,
                'segment_name': 'medium_value_growing',
                'segment_description': '–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–Ω–æ—Å—Ç—å, —Ä–∞—Å—Ç—É—â–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª',
                'recommendations': ['–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'],
                'confidence': 0.8,
                'key_metrics': {'monetary_potential': 5000000, 'loyalty_level': '—Å—Ä–µ–¥–Ω–∏–π'}
            }
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤
        samples = {
            'location_analysis': location_pred,
            'demand_forecast': demand_pred,
            'client_segmentation': segment_pred
        }
        
        os.makedirs('reports', exist_ok=True)
        with open('reports/sample_predictions.json', 'w', encoding='utf-8') as f:
            json.dump(samples, f, indent=2, ensure_ascii=False)
        
        print("‚úÖ –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ reports/sample_predictions.json")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {e}")
        print(f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    start_time = time.time()
    
    print("üéØ –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ï–ô –î–õ–Ø MVP –ê–õ–¨–§–ê-–ë–ê–ù–ö–ê")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    create_directories()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
    data_files = [
        'data/synthetic/locations_data.json',
        'data/synthetic/demand_forecast_data.json', 
        'data/synthetic/b2b_segmentation_data.json'
    ]
    
    missing_files = [f for f in data_files if not os.path.exists(f)]
    
    if missing_files:
        print("‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–¢ –ù–ï–û–ë–•–û–î–ò–ú–´–ï –§–ê–ô–õ–´ –° –î–ê–ù–ù–´–ú–ò:")
        for file in missing_files:
            print(f"  - {file}")
        print("\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞")
        return
    
    print("‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    success_count = 0
    
    if train_location_model():
        success_count += 1
    
    if train_demand_model():
        success_count += 1
    
    if train_segmentation_model():
        success_count += 1
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤
    if success_count > 0:
        generate_sample_predictions()
    
    # –ò—Ç–æ–≥–∏
    end_time = time.time()
    total_time = end_time - start_time
    
    print("\n" + "=" * 60)
    print(f"üèÅ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {success_count}/3")
    print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
    print("=" * 60)
    
    if success_count == 3:
        print("\nüéâ –í–°–ï –ú–û–î–ï–õ–ò –£–°–ü–ï–®–ù–û –û–ë–£–ß–ï–ù–´!")
        print("–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å API –∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:")
        print("1. API: uvicorn api.main:app --reload --port 8000")
        print("2. –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: streamlit run web/app.py --server.port 8501")
    else:
        print(f"\n‚ö†Ô∏è  –ù–ï–ö–û–¢–û–†–´–ï –ú–û–î–ï–õ–ò –ù–ï –û–ë–£–ß–ï–ù–´ ({3-success_count})")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –æ—à–∏–±–æ–∫ –≤—ã—à–µ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ")
        print("–î–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: python train_models.py")

if __name__ == "__main__":
    main()